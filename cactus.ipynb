{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/images/transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KMP_DUPLICATE_LIB_OK']='True' # fixes error with libiomp5.dll\n",
    "RANDOM_STATE = 42\n",
    "UNZIP_IMAGES = False\n",
    "RESIZE_IMAGES = False\n",
    "MOVE_IMAGES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label = pd.read_csv('data\\\\train.csv')\n",
    "id_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label.groupby('has_cactus').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- The data is skewed towards images that have a cactus\n",
    "- i.e. by always guessing 1, the accuracy would be 75%\n",
    "- Need to augment the `has_cactus == 0` data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate data into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SET_SIZE = 3500 # 20%\n",
    "\n",
    "neg_indices = id_label[id_label['has_cactus'] == 0].index\n",
    "pos_indices = id_label[id_label['has_cactus'] == 1].index\n",
    "\n",
    "neg_val = np.random.choice(neg_indices, VALIDATION_SET_SIZE // 2)\n",
    "pos_val = np.random.choice(pos_indices, VALIDATION_SET_SIZE // 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_label['no_cactus'] = pd.Series(np.ones((id_label.shape[0],)) - id_label['has_cactus'], dtype=np.int64)\n",
    "id_label.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that `no_cactus` is the opposite of `has_cactus`\n",
    "assert id_label['has_cactus'].sum() + id_label['no_cactus'].sum() == id_label.shape[0]\n",
    "id_label.where(id_label['has_cactus'] == id_label['no_cactus']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the validation classes 50:50 in case the model is biased towards predicting positive,\n",
    "# it will perform poorly on the validation set\n",
    "pos_val = id_label.sample(VALIDATION_SET_SIZE // 2, weights='has_cactus', random_state=RANDOM_STATE)\n",
    "neg_val = id_label.sample(VALIDATION_SET_SIZE // 2, weights='no_cactus' , random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('pos count:', pos_val['has_cactus'].sum())\n",
    "print('neg count:', neg_val['no_cactus'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = id_label.drop(pos_val.index).drop(neg_val.index)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.concat([pos_val, neg_val])\n",
    "val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['has_cactus'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_count, neg_count = train_df['has_cactus'].value_counts().array\n",
    "\n",
    "print(f'Pos:Neg ratio = {pos_count / neg_count:.2f}', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- About 4x as many positives as negitives\n",
    "- Can increase the weight of a negative by 4\n",
    "- Could downsample but this may reduce the training data too much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(src: Path, new_size: tuple[int, int]):\n",
    "    for img_path in src.iterdir():\n",
    "        with Image.open(img_path, 'r') as img:\n",
    "            resized = img.resize(new_size)\n",
    "        resized.save(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_images_to_folder(src: Path, dst:Path, df: pd.DataFrame) -> None:\n",
    "    has_cactus = dst.joinpath('has_cactus')\n",
    "    no_cactus = dst.joinpath('no_cactus')\n",
    "\n",
    "    ensure_folders_exist([has_cactus, no_cactus])\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        if i in df.index:\n",
    "            img_path = src.joinpath(row['id'])\n",
    "            move_to_class_folder(img_path, [has_cactus, no_cactus], row)\n",
    "\n",
    "\n",
    "def ensure_folders_exist(paths: list[Path]) -> None:\n",
    "    for path in paths:\n",
    "        if not path.parent.exists():\n",
    "            path.parent.mkdir()\n",
    "        if not path.exists():\n",
    "            path.mkdir()\n",
    "\n",
    "\n",
    "def move_to_class_folder(img_path: Path, class_dirs: list[Path], row: pd.Series) -> None:\n",
    "    if row['has_cactus'] == 1:\n",
    "        img_path.rename(class_dirs[0].joinpath(row['id']))\n",
    "    else:\n",
    "        img_path.rename(class_dirs[1].joinpath(row['id']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_ZIP = Path('data\\\\train.zip')\n",
    "TRAIN_DIR  = Path('data\\\\train')\n",
    "VAL_DIR = Path('data\\\\validation')\n",
    "IMG_SIZE = (96, 96)\n",
    "\n",
    "if UNZIP_IMAGES:\n",
    "    with zipfile.ZipFile(TRAIN_ZIP, 'r') as my_zip:\n",
    "        my_zip.extractall(TRAIN_ZIP.parent)\n",
    "\n",
    "if RESIZE_IMAGES:\n",
    "    resize_images(TRAIN_DIR, IMG_SIZE) # images come in `train.zip` so are extracted to `train`\n",
    "\n",
    "if MOVE_IMAGES:\n",
    "    move_images_to_folder(TRAIN_DIR, TRAIN_DIR, train_df)\n",
    "    move_images_to_folder(TRAIN_DIR, VAL_DIR, val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(src: Path) -> int:\n",
    "    count = 0\n",
    "    for path in src.iterdir():\n",
    "        if path.is_dir():\n",
    "            count += count_images(path)\n",
    "        elif path.is_file():\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "print(count_images(TRAIN_DIR))\n",
    "print(count_images(VAL_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correct amount of images in each path\n",
    "assert count_images(VAL_DIR.joinpath('has_cactus')) == val_df['has_cactus'].sum()\n",
    "assert count_images(VAL_DIR.joinpath('no_cactus')) == val_df['no_cactus'].sum()\n",
    "assert count_images(TRAIN_DIR.joinpath('has_cactus')) == train_df['has_cactus'].sum()\n",
    "assert count_images(TRAIN_DIR.joinpath('no_cactus')) == train_df['no_cactus'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = keras.utils.image_dataset_from_directory(TRAIN_DIR,\n",
    "                                                        shuffle=True,\n",
    "                                                        batch_size=BATCH_SIZE,\n",
    "                                                        image_size=IMG_SIZE)\n",
    "\n",
    "val_dataset = keras.utils.image_dataset_from_directory(VAL_DIR,\n",
    "                                                       shuffle=True,\n",
    "                                                       batch_size=BATCH_SIZE,\n",
    "                                                       image_size=IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = train_dataset.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_dataset.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "# test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    keras.layers.RandomFlip('horizontal'),\n",
    "    keras.layers.RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, _ in train_dataset.take(1):\n",
    "  plt.figure(figsize=(10, 10))\n",
    "  first_image = image[0]\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    augmented_image = data_augmentation(tf.expand_dims(first_image, 0))\n",
    "    plt.imshow(augmented_image[0] / 255)\n",
    "    plt.axis('off')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changes the range of pixes values to [-1, 1] for MobileNet\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
